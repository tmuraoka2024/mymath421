
---
output: 
  html_document:
  pdf_document: default
  word_document: default
title: "Assignment 14 - Extra: Networks of Words"
---

***How to do it?***: 

- Open the Rmarkdown file of this assignment ([link](assignment14_extra.Rmd)) in Rstudio. 

- Right under each **question**, insert  a code chunk (you can use the hotkey `Ctrl + Alt + I` to add a code chunk) and code the solution for the question. 

- `Knit` the rmarkdown file (hotkey: `Ctrl + Alt + K`) to export an html.  

-  Publish the html file to your Githiub Page. 

***Submission***: Submit the link on Github of the assignment to Canvas

```{r setup, include=FALSE}
knitr::opts_chunk$set(message = FALSE, warning = FALSE, cache = TRUE)
```

-------

Following [this document](https://www.tidytextmining.com/nasa) to plot a network of words for one of the text datasets.

```{r}
library(jsonlite)
metadata <- fromJSON("https://data.nasa.gov/data.json")
names(metadata$dataset)
```

```{r}
class(metadata$dataset$title)
```

```{r}
class(metadata$dataset$description)
```

```{r}
class(metadata$dataset$keyword)
```

```{r}
library(dplyr)

nasa_title <- tibble(id = metadata$dataset$identifier, 
                     title = metadata$dataset$title)
nasa_title
```

```{r}
nasa_desc <- tibble(id = metadata$dataset$identifier, 
                    desc = metadata$dataset$description)

nasa_desc %>% 
  select(desc) %>% 
  sample_n(5)
```

```{r}
library(tidyr)

nasa_keyword <- tibble(id = metadata$dataset$identifier, 
                       keyword = metadata$dataset$keyword) %>%
  unnest(keyword)

nasa_keyword
```

```{r}
library(ggplot2)

nasa_keyword %>% 
  count(keyword, sort = TRUE) %>% 
  filter(nchar(keyword)>1) %>% 
  head(20) %>% 
  ggplot(aes(x = n, y = reorder(keyword, n))) +
  geom_col(fill='dodgerblue') +
  labs(y = '', x = 'Frequency')
```

```{r}
library(tidytext)

nasa_title <- nasa_title %>% 
  unnest_tokens(word, title) %>% 
  anti_join(stop_words)

nasa_desc <- nasa_desc %>% 
  unnest_tokens(word, desc) %>% 
  anti_join(stop_words)
```

```{r}
nasa_title
```

```{r}
nasa_desc
```

```{r}
nasa_title %>%
  count(word, sort = TRUE)
```


```{r}
nasa_title %>% 
  count(word, sort = TRUE) %>% 
  filter(nchar(word)>1) %>% 
  head(20) %>% 
  ggplot(aes(x = n, y = reorder(word, n))) +
  geom_col(fill='lightgreen') +
  labs(y = '', x = 'Frequency')
```
```{r}
nasa_desc %>%
  count(word, sort = TRUE)
```


```{r}
nasa_desc %>% 
  count(word, sort = TRUE) %>% 
  filter(nchar(word)>1) %>% 
  head(20) %>% 
  ggplot(aes(x = n, y = reorder(word, n))) +
  geom_col(fill='darkred') +
  labs(y = '', x = 'Frequency')
```
```{r}
my_stopwords <- tibble(word = c(as.character(1:10), 
                                "v1", "v1.0","v03", "l2", "l3", "l4", "v5.2.0", 
                                "v003", "v004", "v005", "v006", "v7", "v2.0"))
nasa_title <- nasa_title %>% 
  anti_join(my_stopwords)
nasa_desc <- nasa_desc %>% 
  anti_join(my_stopwords)
```

```{r}
nasa_keyword %>% 
  group_by(keyword) %>% 
  count(sort = TRUE)
```

```{r}
nasa_keyword <- nasa_keyword %>% 
  mutate(keyword = toupper(keyword))
```


```{r}
nasa_title %>%
  count(word, sort = TRUE)
```

```{r}
nasa_title %>% 
  count(word, sort = TRUE) %>% 
  filter(nchar(word)>1) %>% 
  head(20) %>% 
  ggplot(aes(x = n, y = reorder(word, n))) +
  geom_col(fill='orange') +
  labs(y = '', x = 'Frequency')
```

```{r}
nasa_desc %>%
  count(word, sort = TRUE)
```

```{r}
nasa_desc %>% 
  count(word, sort = TRUE) %>% 
  filter(nchar(word)>1) %>% 
  head(20) %>% 
  ggplot(aes(x = n, y = reorder(word, n))) +
  geom_col(fill='blue') +
  labs(y = '', x = 'Frequency')
```




```{r}
library(wordcloud) 
pal <- brewer.pal(8,"Dark2")

nasa_title %>%
  count(word, sort = TRUE) %>%
  filter(nchar(word)>1) %>% 
  with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
```

```{r}
pal <- brewer.pal(8,"Dark2")

nasa_desc %>%
  count(word, sort = TRUE) %>%
  filter(nchar(word)>1) %>% 
  with(wordcloud(word, n, random.order = FALSE, max.words = 50, colors=pal))
```
```{r}
library(widyr)

title_word_pairs <- nasa_title %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE)

title_word_pairs
```

```{r}
desc_word_pairs <- nasa_desc %>% 
  pairwise_count(word, id, sort = TRUE, upper = FALSE)

desc_word_pairs
```


```{r}
library(igraph)
library(ggraph)

set.seed(1234)
title_word_pairs %>%
  filter(n >= 250) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "cyan4") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE, 
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```

```{r}
set.seed(1234)
desc_word_pairs %>%
  filter(n >= 2500) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "darkred") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE,
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```

```{r}
keyword_pairs <- nasa_keyword %>% 
  pairwise_count(keyword, id, sort = TRUE, upper = FALSE)

keyword_pairs
```

```{r}
set.seed(1234)
keyword_pairs %>%
  filter(n >= 700) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = n, edge_width = n), edge_colour = "royalblue") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE,
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```
```{r}
keyword_cors <- nasa_keyword %>% 
  group_by(keyword) %>%
  filter(n() >= 50) %>%
  pairwise_cor(keyword, id, sort = TRUE, upper = FALSE)

keyword_cors
```

```{r}
set.seed(1234)
keyword_cors %>%
  filter(correlation > .8) %>%
  graph_from_data_frame() %>%
  ggraph(layout = "fr") +
  geom_edge_link(aes(edge_alpha = correlation, edge_width = correlation), edge_colour = "royalblue") +
  geom_node_point(size = 5) +
  geom_node_text(aes(label = name), repel = TRUE,
                 point.padding = unit(0.2, "lines")) +
  theme_void()
```
```






























